{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"wB8dB2PxJJ7-"},"outputs":[],"source":["%matplotlib inline"]},{"cell_type":"markdown","metadata":{"id":"wGKnwaPmJJ8C"},"source":["\n","\n","Tensors\n","==========================\n","\n","Tensors are a specialized data structure that are very similar to arrays and matrices.\n","In PyTorch, we use tensors to encode the inputs and outputs of a model, as well as the model’s parameters.\n","\n","Tensors are similar to `NumPy’s ndarrays, except that **tensors can run on GPUs or other hardware accelerators.** \n","\n","- tensors and NumPy arrays can often share the same underlying memory, eliminating the need to copy data (see `bridge-to-np-label`). \n","- Tensors\n","are also optimized for automatic differentiation. Which is critical for deep learning!\n","\n","![picture](https://drive.google.com/uc?id=1inz8rB_q_mGuSsYz5dRl4C9-9qLTg5Xm)"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"9H3zGAZCJJ8D","executionInfo":{"status":"ok","timestamp":1648602297017,"user_tz":-540,"elapsed":7635,"user":{"displayName":"CDJ","userId":"01646918403990549302"}}},"outputs":[],"source":["import torch\n","import numpy as np"]},{"cell_type":"markdown","metadata":{"id":"we97KHhwJJ8E"},"source":["## Initializing a Tensor\n","\n","Tensors can be initialized in various ways. Take a look at the following examples:\n","\n","**Directly from data**\n","\n","Tensors can be created directly from data. The data type is automatically inferred.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VgLJ-QKYJJ8E","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1648521954801,"user_tz":-540,"elapsed":2,"user":{"displayName":"CDJ","userId":"01646918403990549302"}},"outputId":"f25f3769-0346-42b2-df7b-1ab83437b695"},"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[1, 2],\n","        [3, 4]])\n"]}],"source":["data = [[1, 2],[3, 4]]\n","x_data = torch.tensor(data)\n","print(x_data)"]},{"cell_type":"markdown","metadata":{"id":"BFVJ7liTJJ8E"},"source":["**From a NumPy array**\n","\n","Tensors can be created from NumPy arrays (and vice versa).\n","\n","This becomes handy when you would want to pre-process on NumPy using many of Numpy functions and convert to Tensor for GPU advantageous functions.\n","Same goes for post-processing! (converting Tensor to NumPy)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"q6RyZM4bJJ8F"},"outputs":[],"source":["np_array = np.array(data)\n","x_np = torch.from_numpy(np_array)"]},{"cell_type":"markdown","metadata":{"id":"Smfse93kJJ8G"},"source":["**From another tensor creating operation:**\n","\n","The new tensor retains the properties (shape, datatype) of the argument tensor, unless explicitly overridden.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AYAUm8DkJJ8G","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1648522018841,"user_tz":-540,"elapsed":267,"user":{"displayName":"CDJ","userId":"01646918403990549302"}},"outputId":"197eb40c-6d73-4e1c-b791-3a646a907c93"},"outputs":[{"output_type":"stream","name":"stdout","text":["Ones Tensor: \n"," tensor([[1, 1],\n","        [1, 1]]) \n","\n","Random Tensor: \n"," tensor([[0.2621, 0.5799],\n","        [0.6417, 0.2297]]) \n","\n"]}],"source":["x_ones = torch.ones_like(x_data) # retains the properties of x_data\n","print(f\"Ones Tensor: \\n {x_ones} \\n\")\n","\n","x_rand = torch.rand_like(x_data, dtype=torch.float) # overrides the datatype of x_data\n","print(f\"Random Tensor: \\n {x_rand} \\n\")"]},{"cell_type":"markdown","metadata":{"id":"APk23BUAJJ8H"},"source":["**With random or constant values:**\n","\n","``shape`` is a tuple of tensor dimensions. In the functions below, it determines the dimensionality of the output tensor.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kDN97kT7JJ8H","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1648522023042,"user_tz":-540,"elapsed":270,"user":{"displayName":"CDJ","userId":"01646918403990549302"}},"outputId":"5e4cf6ae-9a26-49a3-9051-9bf683f47cb3"},"outputs":[{"output_type":"stream","name":"stdout","text":["Random Tensor: \n"," tensor([[0.4701, 0.6289, 0.6239],\n","        [0.5850, 0.3134, 0.1547]]) \n","\n","Ones Tensor: \n"," tensor([[1., 1., 1.],\n","        [1., 1., 1.]]) \n","\n","Zeros Tensor: \n"," tensor([[0., 0., 0.],\n","        [0., 0., 0.]])\n"]}],"source":["shape = (2,3,)\n","rand_tensor = torch.rand(shape)\n","ones_tensor = torch.ones(shape)\n","zeros_tensor = torch.zeros(shape)\n","\n","print(f\"Random Tensor: \\n {rand_tensor} \\n\")\n","print(f\"Ones Tensor: \\n {ones_tensor} \\n\")\n","print(f\"Zeros Tensor: \\n {zeros_tensor}\")"]},{"cell_type":"markdown","metadata":{"id":"_byws98pJJ8I"},"source":["## Attributes of a Tensor\n","\n","Tensor attributes describe their **shape, datatype, and the device** on which they are stored.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wXnnC-2vJJ8I","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1648522028145,"user_tz":-540,"elapsed":285,"user":{"displayName":"CDJ","userId":"01646918403990549302"}},"outputId":"274b1ff0-a6f5-40f7-f955-865f58a5a784"},"outputs":[{"output_type":"stream","name":"stdout","text":["Shape of tensor: torch.Size([3, 4])\n","Datatype of tensor: torch.float32\n","Device tensor is stored on: cpu\n"]}],"source":["tensor = torch.rand(3,4)\n","\n","print(f\"Shape of tensor: {tensor.shape}\")\n","print(f\"Datatype of tensor: {tensor.dtype}\")\n","print(f\"Device tensor is stored on: {tensor.device}\")"]},{"cell_type":"markdown","metadata":{"id":"aE2ejTGDJJ8J"},"source":["## Operations on Tensors\n","\n","Over 100 tensor operations, including arithmetic, linear algebra, matrix manipulation (transposing,\n","indexing, slicing), sampling and more are\n","comprehensively described [here](https://pytorch.org/docs/stable/torch.html).\n","\n","Each of these operations can be run on the GPU (at typically higher speeds than on a CPU!). \n","\n","If you’re using Colab, allocate a GPU by going to `Runtime > Change runtime type > GPU`.\n","\n","By default, tensors are created on the CPU. We need to explicitly move tensors to the GPU using\n","``.to`` method (after checking for GPU availability). Keep in mind that copying large tensors\n","across devices can be expensive in terms of time and memory!\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gPQV9MxsJJ8J","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1648522204654,"user_tz":-540,"elapsed":394,"user":{"displayName":"CDJ","userId":"01646918403990549302"}},"outputId":"21cdbfe1-f25f-406b-e582-1f9e0ead3ee5"},"outputs":[{"output_type":"stream","name":"stdout","text":["Device tensor is stored on: cpu\n"]}],"source":["tensor = torch.rand(3,4) # re-init random tensor\n","# We move our tensor to the GPU if available\n","if torch.cuda.is_available():\n","    tensor = tensor.to(\"cuda\")\n","print(f\"Device tensor is stored on: {tensor.device}\")"]},{"cell_type":"markdown","metadata":{"id":"vdgPa2r6JJ8J"},"source":["Try out some of the operations from the list.\n","If you're familiar with the NumPy API, you'll find the Tensor API a breeze to use.\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"dhCr1XvyJJ8J"},"source":["**Standard numpy-like indexing and slicing:**\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"D1gEywihJJ8K","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1648522256660,"user_tz":-540,"elapsed":6,"user":{"displayName":"CDJ","userId":"01646918403990549302"}},"outputId":"22af1812-1dfe-437b-c76a-ef36c7614e52"},"outputs":[{"output_type":"stream","name":"stdout","text":["First row: tensor([1., 1., 1., 1.])\n","First column: tensor([1., 1., 1., 1.])\n","Last column: tensor([1., 1., 1., 1.])\n","tensor([[1., 0., 1., 1.],\n","        [1., 0., 1., 1.],\n","        [1., 0., 1., 1.],\n","        [1., 0., 1., 1.]])\n"]}],"source":["tensor = torch.ones(4, 4)\n","print(f\"First row: {tensor[0]}\")\n","print(f\"First column: {tensor[:, 0]}\")\n","print(f\"Last column: {tensor[..., -1]}\")\n","\n","# remember [row x column]. So select all rows in selected 1 column and set it to 0.\n","tensor[:,1] = 0 \n","print(tensor)"]},{"cell_type":"markdown","metadata":{"id":"4-g1IJ-lJJ8K"},"source":["**Joining tensors** You can use ``torch.cat`` to concatenate a sequence of tensors along a given dimension.\n","See also [torch.stack](https://pytorch.org/docs/stable/generated/torch.stack.html)\n","another tensor joining op that is subtly different from ``torch.cat``.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pWkMmAt7JJ8K","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1648522295300,"user_tz":-540,"elapsed":287,"user":{"displayName":"CDJ","userId":"01646918403990549302"}},"outputId":"836634da-fe19-4e41-c9a2-da550e8012d6"},"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n","        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n","        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n","        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.]])\n"]}],"source":["t1 = torch.cat([tensor, tensor, tensor], dim=1)\n","print(t1)"]},{"cell_type":"markdown","metadata":{"id":"0QfZ2ZCAJJ8K"},"source":["**Arithmetic operations**\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CWxWN9pVJJ8K","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1648522309834,"user_tz":-540,"elapsed":379,"user":{"displayName":"CDJ","userId":"01646918403990549302"}},"outputId":"c4f2f792-de71-41fa-a844-41ee902271a8"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[1., 0., 1., 1.],\n","        [1., 0., 1., 1.],\n","        [1., 0., 1., 1.],\n","        [1., 0., 1., 1.]])"]},"metadata":{},"execution_count":20}],"source":["# This computes the matrix multiplication between two tensors. y1, y2, y3 will have the same value\n","y1 = tensor @ tensor.T\n","y2 = tensor.matmul(tensor.T)\n","\n","y3 = torch.rand_like(tensor)\n","torch.matmul(tensor, tensor.T, out=y3)\n","\n","\n","# This computes the element-wise product. z1, z2, z3 will have the same value\n","z1 = tensor * tensor\n","z2 = tensor.mul(tensor)\n","\n","z3 = torch.rand_like(tensor)\n","torch.mul(tensor, tensor, out=z3)"]},{"cell_type":"markdown","metadata":{"id":"L_HTgPBHJJ8K"},"source":["**Single-element tensors** If you have a one-element tensor, for example by aggregating all\n","values of a tensor into one value, you can convert it to a Python\n","numerical value using ``item()``:\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3cbJAkJfJJ8L","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1648522319302,"user_tz":-540,"elapsed":416,"user":{"displayName":"CDJ","userId":"01646918403990549302"}},"outputId":"8ce585b5-1d65-4e2f-f371-5fa73568bff7"},"outputs":[{"output_type":"stream","name":"stdout","text":["12.0 <class 'float'>\n"]}],"source":["agg = tensor.sum()\n","agg_item = agg.item()\n","print(agg_item, type(agg_item))"]},{"cell_type":"markdown","metadata":{"id":"lHLZIEi4JJ8L"},"source":["**In-place operations**\n","Operations that store the result into the operand are called in-place. \n","\n","Normally, python will copy and create new memory for new variables, using an in-place operation, no new memory will be used.\n","They are denoted by a ``_`` suffix.\n","\n","For example: ``x.copy_(y)``, ``x.t_()``, will change ``x``.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"f64CWKBGJJ8L","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1648522358734,"user_tz":-540,"elapsed":324,"user":{"displayName":"CDJ","userId":"01646918403990549302"}},"outputId":"7d3e2a59-1fb1-41ee-c19b-f747832aa310"},"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[1., 0., 1., 1.],\n","        [1., 0., 1., 1.],\n","        [1., 0., 1., 1.],\n","        [1., 0., 1., 1.]]) \n","\n","tensor([[6., 5., 6., 6.],\n","        [6., 5., 6., 6.],\n","        [6., 5., 6., 6.],\n","        [6., 5., 6., 6.]])\n"]}],"source":["print(f\"{tensor} \\n\")\n","tensor.add_(5)\n","print(tensor)"]},{"cell_type":"markdown","metadata":{"id":"1KDjBwQQJJ8L"},"source":["**Note** In-place operations save some memory, but can be problematic when computing derivatives because of an immediate loss of history. Hence, their use is discouraged.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"ciXchZhnJJ8L"},"source":["\n","## Bridge with NumPy\n","Tensors on the CPU and NumPy arrays can *__share__ their underlying memory\n","locations*, and changing one will change\tthe other.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"V6PwlhYAJJ8L"},"source":["Tensor to NumPy array\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UNx2CEQuJJ8L","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1648522525914,"user_tz":-540,"elapsed":295,"user":{"displayName":"CDJ","userId":"01646918403990549302"}},"outputId":"e898dd2b-b055-40b9-f3ca-2ed1f721e57f"},"outputs":[{"output_type":"stream","name":"stdout","text":["t: tensor([1., 1., 1., 1., 1.])\n","n: [1. 1. 1. 1. 1.]\n"]}],"source":["t = torch.ones(5)\n","print(f\"t: {t}\")\n","n = t.numpy()\n","print(f\"n: {n}\")"]},{"cell_type":"markdown","metadata":{"id":"Cu655EsoJJ8L"},"source":["A change in the tensor is also reflected in the NumPy array. (because they share the memory)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VYR_uYf0JJ8L","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1648522528603,"user_tz":-540,"elapsed":353,"user":{"displayName":"CDJ","userId":"01646918403990549302"}},"outputId":"23ded9a7-0edb-4729-c726-f9d40a99126b"},"outputs":[{"output_type":"stream","name":"stdout","text":["t: tensor([2., 2., 2., 2., 2.])\n","n: [2. 2. 2. 2. 2.]\n"]}],"source":["t.add_(1)\n","print(f\"t: {t}\")\n","print(f\"n: {n}\")"]},{"cell_type":"markdown","metadata":{"id":"gMhGSyc8JJ8L"},"source":["NumPy array to Tensor"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EtBf_j32JJ8M"},"outputs":[],"source":["n = np.ones(5)\n","t = torch.from_numpy(n)"]},{"cell_type":"markdown","metadata":{"id":"0YLswjKjJJ8M"},"source":["Changes in the NumPy array reflects in the tensor.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2jmgYXdgJJ8M","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1648522544637,"user_tz":-540,"elapsed":300,"user":{"displayName":"CDJ","userId":"01646918403990549302"}},"outputId":"7d066fc5-e898-4f16-d64c-b7afb6703166"},"outputs":[{"output_type":"stream","name":"stdout","text":["t: tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n","n: [2. 2. 2. 2. 2.]\n"]}],"source":["np.add(n, 1, out=n)\n","print(f\"t: {t}\")\n","print(f\"n: {n}\")"]},{"cell_type":"markdown","source":["## Quiz\n"],"metadata":{"id":"4M-Eohy5V9HM"}},{"cell_type":"markdown","source":["1. Create a random tensor called `rand_tensor`, tensor of all 1s called `one_tensor`, tensor of all 0s called `zero_tensor` ALL of size `3 x 4`, and print the tensors, and print its attributes (recall: device, datatype, shape). If the tensor is on CPU, place it on GPU!"],"metadata":{"id":"DMJe_fgaWKeh"}},{"cell_type":"code","source":["rand_tensor = torch.rand(3,4)\n","one_tensor = torch.ones(3,4)\n","zero_tensor = torch.zeros(3,4)\n","\n","print(rand_tensor)\n","print(one_tensor)\n","print(zero_tensor)\n","print(f\"Shape of tensor: {rand_tensor.shape}\")\n","print(f\"Datatype of tensor: {rand_tensor.dtype}\")\n","print(f\"Device tensor is stored on: {rand_tensor.device}\")\n","if torch.cuda.is_available():\n","    gpu_rand_tensor = rand_tensor.to(\"cuda\")\n","print(f\"Device tensor is stored on: {gpu_rand_tensor.device}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":415},"id":"AvFgOdJfV_mS","executionInfo":{"status":"error","timestamp":1648603050221,"user_tz":-540,"elapsed":674,"user":{"displayName":"CDJ","userId":"01646918403990549302"}},"outputId":"dd5b291d-60e5-47cf-d961-a0875fb2d90d"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[0.8558, 0.8993, 0.7481, 0.1362],\n","        [0.5445, 0.6361, 0.1251, 0.2134],\n","        [0.8967, 0.0248, 0.8069, 0.2765]])\n","tensor([[1., 1., 1., 1.],\n","        [1., 1., 1., 1.],\n","        [1., 1., 1., 1.]])\n","tensor([[0., 0., 0., 0.],\n","        [0., 0., 0., 0.],\n","        [0., 0., 0., 0.]])\n","Shape of tensor: torch.Size([3, 4])\n","Datatype of tensor: torch.float32\n","Device tensor is stored on: cpu\n"]},{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-945ae0c1ab57>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mgpu_rand_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrand_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Device tensor is stored on: {gpu_rand_tensor.device}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'gpu_rand_tensor' is not defined"]}]},{"cell_type":"markdown","source":["2. create a numpy array of all 1s of size `3 x 4`. Convert them to pytorch Tensors, print the tensors & its attributes. Again if the tensor is on CPU, place it on GPU!"],"metadata":{"id":"gxrOGyOLX_0M"}},{"cell_type":"code","source":["one_numpy = np.ones((3,4))\n","one_tensor = torch.from_numpy(one_numpy)\n","print(one_tensor)\n","print(f\"Shape of tensor: {one_tensor.shape}\")\n","print(f\"Datatype of tensor: {one_tensor.dtype}\")\n","print(f\"Device tensor is stored on: {one_tensor.device}\")\n","if torch.cuda.is_available():\n","    gpu_one_tensor = one_tensor.to(\"cuda\")\n","print(f\"Device tensor is stored on: {gpu_one_tensor.device}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EUWdbSDeV_zC","executionInfo":{"status":"ok","timestamp":1648436233306,"user_tz":-540,"elapsed":3,"user":{"displayName":"CDJ","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhhNCRY_P6sYQaPX9YUmgkXmQwldQsBwHlEzRWlKg=s64","userId":"01646918403990549302"}},"outputId":"dcd992cc-b7ad-467e-f73a-0b633f29dd26"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[1., 1., 1., 1.],\n","        [1., 1., 1., 1.],\n","        [1., 1., 1., 1.]], dtype=torch.float64)\n","Shape of tensor: torch.Size([3, 4])\n","Datatype of tensor: torch.float64\n","Device tensor is stored on: cpu\n","Device tensor is stored on: cuda:0\n"]}]},{"cell_type":"markdown","source":["3. We are going to do matrix multiplication. Create a Tensor that is able to multiply to our `one_tensor` created above, and perform the matrix multiplication."],"metadata":{"id":"U-oHZe-TZDDV"}},{"cell_type":"code","source":["one_tensor.shape\n","tmp_tensor = torch.ones(4,3, dtype=torch.double)\n","matmuled = one_tensor @ tmp_tensor\n","print(f\"Matrix multiplied tensor shape: {matmuled.shape}\")\n","print(matmuled)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"O_sxOt03V_9A","executionInfo":{"status":"ok","timestamp":1648436961575,"user_tz":-540,"elapsed":1,"user":{"displayName":"CDJ","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhhNCRY_P6sYQaPX9YUmgkXmQwldQsBwHlEzRWlKg=s64","userId":"01646918403990549302"}},"outputId":"0cccff34-3b4d-40bb-cc4f-fc6c655481a9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Matrix multiplied tensor shape: torch.Size([3, 3])\n","tensor([[4., 4., 4.],\n","        [4., 4., 4.],\n","        [4., 4., 4.]], dtype=torch.float64)\n"]}]},{"cell_type":"markdown","source":["4. Create a Tensor to \"concatenate\" to the row (first dimension) of our `zero_tensor` above. Create another Tensor to \"stack\" on `dim=0` to our `zero_tensor` as well. Print the shapes of all created tensors. "],"metadata":{"id":"fbS7iiq3ZiqC"}},{"cell_type":"code","source":["zero_tensor = torch.zeros(3,4)\n","print(zero_tensor.shape)\n","concat_tensor = torch.ones(3,4)\n","concatted = torch.concat((zero_tensor, concat_tensor), dim=0)\n","print(f'Concatted tensor is now of shape: {concatted.shape}')\n","\n","stacked = torch.stack((concat_tensor, zero_tensor), dim=0)\n","print(f'Stacked tensor is now of shape: {stacked.shape}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iwEYJ5obWAJK","executionInfo":{"status":"ok","timestamp":1648603461280,"user_tz":-540,"elapsed":267,"user":{"displayName":"CDJ","userId":"01646918403990549302"}},"outputId":"98f73d05-108b-4cdb-f74a-1d1a8255d79a"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([3, 4])\n","Concatted tensor is now of shape: torch.Size([6, 4])\n","Stacked tensor is now of shape: torch.Size([2, 3, 4])\n"]}]},{"cell_type":"markdown","source":["5. Create a tensor of size (3,4) and [reshape](https://pytorch.org/docs/stable/generated/torch.reshape.html#torch.reshape) it to (6,2). Print the resulting shape of the tensor."],"metadata":{"id":"1iuq9jpeaIjt"}},{"cell_type":"code","source":["rand_tensor = torch.rand(3,4)\n","reshaped = rand_tensor.reshape(6,2)\n","print(rand_tensor)\n","print(reshaped)\n","print(reshaped.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"N1Dd8vzsWB_O","executionInfo":{"status":"ok","timestamp":1648603624598,"user_tz":-540,"elapsed":4,"user":{"displayName":"CDJ","userId":"01646918403990549302"}},"outputId":"432145a3-33bb-4805-a877-2c025f399d40"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[0.5886, 0.0751, 0.4077, 0.5222],\n","        [0.5586, 0.0508, 0.0102, 0.4679],\n","        [0.6507, 0.2190, 0.5530, 0.0624]])\n","tensor([[0.5886, 0.0751],\n","        [0.4077, 0.5222],\n","        [0.5586, 0.0508],\n","        [0.0102, 0.4679],\n","        [0.6507, 0.2190],\n","        [0.5530, 0.0624]])\n","torch.Size([6, 2])\n"]}]},{"cell_type":"markdown","source":["6. Create a linear interpolation of $x$ values where $0 <= x <= 10$ evenly spaced by 2. (Hint: [linspace](https://pytorch.org/docs/stable/generated/torch.linspace.html#torch.linspace))"],"metadata":{"id":"o7vN7ydmbfBl"}},{"cell_type":"code","source":["print(torch.linspace(0,10,6))\n","# print(torch.lerp(torch.tensor(0, dtype=torch.float), torch.tensor(10, dtype=torch.float), 2))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8rZKrYXNWCF4","executionInfo":{"status":"ok","timestamp":1648604026331,"user_tz":-540,"elapsed":250,"user":{"displayName":"CDJ","userId":"01646918403990549302"}},"outputId":"15e04b83-196e-4988-f75f-a3e8b55a3fc3"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([ 0.,  2.,  4.,  6.,  8., 10.])\n"]}]},{"cell_type":"code","source":[""],"metadata":{"id":"EZCzD0pAc05j"},"execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.11"},"colab":{"name":"1. tensors_sol.ipynb","provenance":[],"collapsed_sections":[]}},"nbformat":4,"nbformat_minor":0}